# Proyecto de Evaluaci√≥n de Modelos ‚Äì Overfitting y Underfitting

## üìå Descripci√≥n

El prop√≥sito de este proyecto es comprender y aplicar t√©cnicas de **evaluaci√≥n y validaci√≥n de modelos de Machine Learning**, poniendo especial √©nfasis en la detecci√≥n y manejo de **overfitting** y **underfitting**. Se utilizan dos problemas reales de clasificaci√≥n: predicci√≥n de fuga de clientes (**churn**) y predicci√≥n de **default** en tarjetas de cr√©dito, cubriendo tanto escenarios balanceados como desbalanceados.

---

## üöÄ Instrucciones de Ejecuci√≥n

### 1. Requisitos previos

Aseg√∫rate de tener instalado:

* Python 3.8 o superior

### 2. Instalaci√≥n de librer√≠as necesarias

Ejecuta en tu entorno de Python:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xlrd
```

### 3. Ejecuci√≥n de los scripts

1. Clona este repositorio:

   ```bash
   git clone https://github.com/MateoM77/AnalisisTaller1.git
   ```
2. Ejecuta los scripts:

   * `Practica_Dataset1.py` ‚Üí An√°lisis y evaluaci√≥n con el dataset de Telco Customer Churn.
   * `Pratica_Dataset2.py` ‚Üí An√°lisis y evaluaci√≥n con el dataset de Credit Card Default.

### 4. Archivos generados

Al finalizar la ejecuci√≥n de cada script, se generan autom√°ticamente visualizaciones (matriz de confusi√≥n, curvas ROC, curvas de aprendizaje) y reportes de m√©tricas en consola.

---

## üóÇÔ∏è Datasets Utilizados

1. **Telco Customer Churn ‚Äì Kaggle** (`Dataset 1 Telco Customer Churn - Kaggle.csv`)
   * Datos de clientes de una empresa de telecomunicaciones, objetivo: predecir fuga (churn).
   * Problema de clasificaci√≥n **balanceado**.
   * Incluye variables num√©ricas y categ√≥ricas, ideal para comparar modelos b√°sicos y complejos.

2. **Credit Card Default ‚Äì UCI** (`Dataset 2 Credit Card Default - UCI.xls`)
   * Datos de clientes bancarios, objetivo: predecir si incurrir√°n en impago (default).
   * Problema de clasificaci√≥n **desbalanceado**.
   * Requiere t√©cnicas de manejo de desbalance y an√°lisis cuidadoso de m√©tricas.

---

## ‚ú® Pipeline de An√°lisis

### 1. Preprocesamiento y Limpieza

* **Revisi√≥n y manejo de valores nulos** (imputaci√≥n o eliminaci√≥n).
* **Eliminaci√≥n de duplicados**.
* **Conversi√≥n de variables** (por ejemplo, strings a num√©ricos).
* **Codificaci√≥n de variables categ√≥ricas** (binarias y one-hot encoding).
* **Escalado de variables num√©ricas** con MinMaxScaler.

### 2. Divisi√≥n de los Datos

* Separaci√≥n en conjuntos de **entrenamiento** y **prueba** (80/20), manteniendo la proporci√≥n de clases.

### 3. Entrenamiento y Validaci√≥n

* Entrenamiento de **Regresi√≥n Log√≠stica** y **Random Forest** (adem√°s de SVM para el dataset de default).
* **Validaci√≥n cruzada (k-fold y stratified k-fold)** para b√∫squeda de hiperpar√°metros y estimaci√≥n robusta del rendimiento.

### 4. Evaluaci√≥n de Modelos

* M√©tricas principales: **Accuracy, Recall, F1-score, ROC-AUC**.
* **Matriz de confusi√≥n** y **curvas ROC** para interpretaci√≥n visual.
* **Curvas de aprendizaje** para detectar overfitting y underfitting.
* An√°lisis de **importancia de variables** (feature importance y coeficientes).

### 5. Comparaci√≥n de Resultados

* Comparaci√≥n entre modelos y datasets.
* En el caso del default, especial √©nfasis en m√©tricas robustas al desbalance de clases.

---

## üìÇ Archivos del Repositorio

* `Practica_Dataset1.py` ‚Üí An√°lisis y evaluaci√≥n con Telco Customer Churn.
* `Pratica_Dataset2.py` ‚Üí An√°lisis y evaluaci√≥n con Credit Card Default.
* `Dataset 1 Telco Customer Churn - Kaggle.csv` ‚Üí Datos de churn.
* `Dataset 2 Credit Card Default - UCI.xls` ‚Üí Datos de default.
* `README.md` ‚Üí Documento descriptivo del proyecto.

---

## üé• Explicaci√≥n y Justificaci√≥n

El proyecto incluye:

* Presentaci√≥n te√≥rica de **overfitting, underfitting y validaci√≥n cruzada**.
* Justificaci√≥n de m√©tricas seleccionadas seg√∫n el tipo de problema.
* Ejemplos visuales para detectar y explicar el sobreajuste/subajuste.
* Comparaci√≥n de resultados entre problemas balanceados y desbalanceados.

---

## ‚úÖ Conclusiones

* La correcta evaluaci√≥n de modelos es fundamental para evitar falsas expectativas y errores en producci√≥n.
* La **validaci√≥n cruzada** proporciona estimaciones fiables y ayuda a seleccionar hiperpar√°metros √≥ptimos.
* Cada m√©trica resalta un aspecto distinto: es clave elegir la m√°s relevante para el problema.
* Comparar entre diferentes datasets destaca la importancia de abordar el desbalance y la complejidad de datos en Machine Learning.

---


# Proyecto de An√°lisis de Datos ‚Äì Spotify Churn

## üìå Descripci√≥n

El objetivo fue explorar distintas bases de datos, seleccionar la m√°s adecuada, realizar un **An√°lisis Exploratorio de Datos (EDA)** y aplicar t√©cnicas de **preprocesamiento y reducci√≥n de dimensionalidad (PCA)**.

---

## üöÄ Instrucciones de Ejecuci√≥n

### 1. Requisitos previos

Aseg√∫rate de tener instalado:

* Python 3.8 o superior

### 2. Instalaci√≥n de librer√≠as necesarias

Ejecuta en tu entorno de Python:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### 3. Ejecuci√≥n de los notebooks

1. Clona este repositorio:

   ```bash
   git clone https://github.com/MateoM77/AnalisisTaller1.git
   ```
2. Abre los notebooks:

   * `Fase2_EDA.py`
   * `Fase3_Preprocesamiento.py`

### 4. Archivos generados

Al finalizar la ejecuci√≥n, se crean autom√°ticamente:

* `spotify_datos_escalados.csv`
* `spotify_datos_pca.csv`

---

## üóÇÔ∏è Fase 1 ‚Äì Exploraci√≥n de Bases de Datos

Se exploraron tres bases de datos de diferentes tipos:

1. **Conjunto de Datos de Se√±ales de Tr√°nsito** ‚Äì tipo im√°genes.

   * Datos visuales de se√±ales viales.
   * Aplicaci√≥n: clasificaci√≥n de im√°genes en el contexto de seguridad vial.

2. **Dataset Iris** ‚Äì tipo tabular.

   * Dataset cl√°sico con caracter√≠sticas de flores.
   * Aplicaci√≥n: pruebas r√°pidas de clasificaci√≥n y reducci√≥n de dimensionalidad.

3. **Spotify Churn Dataset** ‚Äì tipo texto/tabular.

   * Datos de usuarios de Spotify con informaci√≥n de uso y cancelaci√≥n de suscripci√≥n.
   * Aplicaci√≥n: an√°lisis de churn (abandono) de usuarios.

### ‚úÖ Justificaci√≥n de la elecci√≥n de Spotify Churn

Se seleccion√≥ esta base de datos porque:

* **Tiene muchas variables num√©ricas y categ√≥ricas**, lo que permite aplicar un an√°lisis exploratorio completo.
* Presenta un **problema real de negocio (churn)** altamente relevante en la industria de streaming.
* Ofrece **posibilidades de hip√≥tesis interesantes**, como la relaci√≥n entre el tiempo de escucha, la tasa de skips o el tipo de suscripci√≥n con la probabilidad de abandono.
* Su tama√±o es **manejable para aplicar EDA, preprocesamiento y PCA** sin limitaciones t√©cnicas.

---

## üîé Fase 2 ‚Äì An√°lisis Exploratorio de Datos (EDA)

Con el dataset de Spotify se realizaron los siguientes pasos:

* **Revisi√≥n de valores faltantes**: identificaci√≥n y cuantificaci√≥n de nulos.
* **Detecci√≥n de outliers**: mediante IQR y boxplots.
* **An√°lisis univariado**: distribuci√≥n de variables num√©ricas y categ√≥ricas.
* **An√°lisis multivariado**: correlaciones, scatterplots y mapas de calor.
* **Insights preliminares**:

  * Los usuarios con mayor *skip rate* presentan mayor probabilidad de churn.
  * La suscripci√≥n gratuita y escuchar anuncios se asocian con mayor churn.
  * Escuchar m√∫sica offline se relaciona con menor tasa de churn.

---

## ‚öôÔ∏è Fase 3 ‚Äì Preprocesamiento y Reducci√≥n de Dimensionalidad

1. **Codificaci√≥n de variables categ√≥ricas** con LabelEncoder.
2. **Escalado de datos** con StandardScaler.
3. **Reducci√≥n de dimensionalidad con PCA**:

   * Se redujo el dataset de *n* variables originales a un n√∫mero √≥ptimo de componentes principales.
   * Se retuvo m√°s del **95% de la varianza**.
4. **Visualizaciones** en 2D y 3D para observar la separaci√≥n de usuarios churn y no churn.
5. **Contribuci√≥n de variables** a los componentes principales mediante un heatmap.

---

## üìÇ Entregables en el Repositorio

* `Fase1_BasesdeDatos.pdf` ‚Üí Exploraci√≥n bases de datos de diferente tipo.
* `Fase2_EDA.py` ‚Üí Exploraci√≥n y an√°lisis de datos.
* `Fase3_Preprocesamiento.py` ‚Üí Codificaci√≥n, escalado y PCA.
* `spotify_churn_dataset.csv` ‚Üí Base de datos Spotify churn
* `spotify_datos_escalados.csv` ‚Üí Datos procesados y escalados.
* `spotify_datos_pca.csv` ‚Üí Datos reducidos con PCA.
* `README.md` ‚Üí Documento descriptivo del proyecto.

---

## üé• Video Explicativo

Se incluye un video donde se presentan:

* Las bases exploradas y justificaci√≥n de la elegida.
* Proceso de EDA y preprocesamiento.
* Resultados principales e insights.

---

## ‚úÖ Conclusiones

* La base de datos de **Spotify Churn** permiti√≥ un an√°lisis m√°s completo y aplicable al mundo real.
* El EDA permiti√≥ identificar variables cr√≠ticas asociadas con el abandono de usuarios.
* El preprocesamiento y PCA facilitaron la reducci√≥n de complejidad conservando la varianza.
* Los datos quedaron listos para fases futuras de **modelado predictivo**.
