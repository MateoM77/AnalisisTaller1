# ğŸ“Š AnÃ¡lisis Predictivo de Rendimiento AcadÃ©mico Estudiantil

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de **Machine Learning** para predecir el rendimiento acadÃ©mico de estudiantes utilizando el dataset "Student Grade Prediction" de Kaggle. El anÃ¡lisis incluye exploraciÃ³n de datos (EDA), preprocesamiento avanzado y mÃºltiples modelos de clasificaciÃ³n.

## ğŸ—‚ï¸ Estructura del Proyecto

```
Analisis4/
â”œâ”€â”€ ejercicio1.ipynb          # Notebook principal con anÃ¡lisis completo
â”œâ”€â”€ ejercicio5.ipynb          # AnÃ¡lisis HR Analytics (complementario)
â”œâ”€â”€ README.md                 # DocumentaciÃ³n del proyecto
â””â”€â”€ datos/                    # Directorio para datasets (generado automÃ¡ticamente)
```

## ğŸ“‹ Contenido del AnÃ¡lisis

### 1. **ExploraciÃ³n de Datos (EDA)**
- **Dataset**: 395 estudiantes con 33 variables
- **Variables**: DemogrÃ¡ficas, acadÃ©micas, familiares y sociales
- **Target**: CalificaciÃ³n final (G3) categorizada en 3 niveles:
  - ğŸ”´ **Bajo** (0-10): Rendimiento deficiente
  - ğŸŸ¡ **Medio** (11-14): Rendimiento satisfactorio  
  - ğŸŸ¢ **Alto** (15-20): Rendimiento excelente

### 2. **Preprocesamiento de Datos**
- âœ… **Sin valores faltantes** - Dataset de alta calidad
- ğŸ”§ **CodificaciÃ³n de variables categÃ³ricas**:
  - Label Encoding para variables binarias
  - One-Hot Encoding para variables multicategorÃ­a
- ğŸ“Š **EstandarizaciÃ³n** de variables numÃ©ricas (StandardScaler)
- ğŸ² **DivisiÃ³n estratificada**: 80% entrenamiento, 20% prueba

### 3. **Modelos de Machine Learning**

| Modelo | Accuracy | F1-Score | Precision | Recall | ğŸ† |
|--------|----------|----------|-----------|---------|-----|
| **Random Forest** | 62.03% | 56.71% | 68.58% | 54.75% | â­ |
| **K-Nearest Neighbors** | 53.16% | 49.72% | 50.64% | 53.72% | - |
| **RegresiÃ³n LogÃ­stica** | 51.90% | 47.88% | 47.33% | 48.10% | - |

**ğŸ† Mejor Modelo**: Random Forest con hiperparÃ¡metros optimizados

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos
```bash
Python 3.8+
Jupyter Notebook
```

### Dependencias
```bash
pip install kagglehub pandas numpy matplotlib seaborn scikit-learn scipy
```

### EjecuciÃ³n
```bash
# Clonar/descargar el proyecto
cd Analisis4

# Ejecutar Jupyter Notebook
jupyter notebook ejercicio1.ipynb
```

## ğŸ” Insights Principales

### **Factores MÃ¡s Importantes** (segÃºn Random Forest):
1. **Calificaciones previas** (G1, G2) - Mayor predictor
2. **Ausencias** - Impacto negativo significativo
3. **Tiempo de estudio** - CorrelaciÃ³n positiva
4. **Apoyo familiar** - Factor protector
5. **Consumo de alcohol** - Factor de riesgo

### **Patrones Identificados**:
- ğŸ“ˆ **Estudiantes exitosos**: Pocas ausencias, mayor tiempo de estudio, apoyo familiar
- ğŸ“‰ **Estudiantes en riesgo**: Altas ausencias, bajo apoyo educativo, problemas familiares
- âš–ï¸ **DistribuciÃ³n balanceada**: 27% Bajo, 47% Medio, 26% Alto

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­as |
|-----------|-------------|
| **Datos** | Kaggle API, Pandas, NumPy |
| **VisualizaciÃ³n** | Matplotlib, Seaborn |
| **ML** | Scikit-learn, GridSearchCV |
| **EstadÃ­stica** | SciPy, PCA, t-SNE |
| **Entorno** | Jupyter Notebook, Python |

## ğŸ“ˆ Resultados y Visualizaciones

### **AnÃ¡lisis Exploratorio**:
- ğŸ“Š Distribuciones de variables clave
- ğŸ”— Matriz de correlaciones
- ğŸ‘¥ AnÃ¡lisis por subgrupos (sexo, apoyo educativo, etc.)
- ğŸ“‰ DetecciÃ³n de outliers

### **Machine Learning**:
- ğŸ¯ Matrices de confusiÃ³n por modelo
- ğŸ“ˆ Curvas de aprendizaje
- ğŸŒŸ Importancia de caracterÃ­sticas
- ğŸ” VisualizaciÃ³n PCA y t-SNE

## ğŸ“ Aplicaciones PrÃ¡cticas

### **Para Instituciones Educativas**:
1. **Sistema de Alerta Temprana**: Identificar estudiantes en riesgo
2. **IntervenciÃ³n Personalizada**: Estrategias basadas en factores de riesgo
3. **AsignaciÃ³n de Recursos**: Priorizar apoyo acadÃ©mico
4. **Seguimiento Predictivo**: Monitoreo continuo del progreso

### **Casos de Uso**:
- ğŸš¨ **DetecciÃ³n temprana** de estudiantes en riesgo de fracaso
- ğŸ“‹ **Recomendaciones personalizadas** de intervenciÃ³n
- ğŸ“Š **AnÃ¡lisis de efectividad** de programas educativos
- ğŸ¯ **OptimizaciÃ³n de recursos** de apoyo acadÃ©mico

## ğŸ”® PrÃ³ximos Pasos

### **Mejoras TÃ©cnicas**:
- [ ] Implementar ensemble de modelos
- [ ] OptimizaciÃ³n de hiperparÃ¡metros con Bayesian Optimization
- [ ] AnÃ¡lisis de importancia con SHAP
- [ ] ValidaciÃ³n temporal con datos longitudinales

### **ExpansiÃ³n del AnÃ¡lisis**:
- [ ] Incorporar variables adicionales (socioeconÃ³micas, psicolÃ³gicas)
- [ ] AnÃ¡lisis por cohortes y temporal
- [ ] Sistema de recomendaciones automatizado
- [ ] Dashboard interactivo para educadores

## ğŸ“Š MÃ©tricas de Negocio

### **Impacto Potencial**:
- ğŸ¯ **PrecisiÃ³n de predicciÃ³n**: 62% de estudiantes correctamente clasificados
- ğŸ” **DetecciÃ³n de riesgo**: IdentificaciÃ³n temprana de 55% de casos de bajo rendimiento
- ğŸ’° **ROI estimado**: ReducciÃ³n de 15-25% en tasas de deserciÃ³n
- â° **Tiempo de intervenciÃ³n**: PredicciÃ³n hasta 2 perÃ­odos acadÃ©micos adelante

## ğŸ‘¥ Contribuciones

Proyecto desarrollado como parte del anÃ¡lisis de datos educativos. Contribuciones y mejoras son bienvenidas.

### **CÃ³mo Contribuir**:
1. Fork del proyecto
2. Crear rama de feature (`git checkout -b feature/mejora`)
3. Commit de cambios (`git commit -am 'AÃ±adir nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico y educativo. Los datos utilizados provienen de fuentes pÃºblicas de Kaggle.

## ğŸ“§ Contacto

Para consultas sobre el proyecto o colaboraciones, contacta a travÃ©s de los issues del repositorio.

---

### ğŸ”— **Enlaces Relevantes**:
- [Dataset Original en Kaggle](https://www.kaggle.com/datasets/dipam7/student-grade-prediction)
- [DocumentaciÃ³n de Scikit-learn](https://scikit-learn.org/)
- [Kagglehub Documentation](https://github.com/Kaggle/kagglehub)

---

**â­ Si este proyecto te resulta Ãºtil, no olvides darle una estrella! â­**

*Ãšltima actualizaciÃ³n: Noviembre 2025*